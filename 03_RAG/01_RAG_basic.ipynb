{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 문서 로드(Load Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\20114\\miniforge3\\envs\\langchain_env\\lib\\site-packages (1.24.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지 수 : 6\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "#PYMUPDFLoader 객체 정의\n",
    "loader = PyMuPDFLoader(\"data/snow-white.pdf\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 페이지 수 : {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왕자는깨어난백설공주를보고기뻐했어요.\n",
      "“공주님, 나는이웃나라왕자입니다.”\n",
      "“왕자님이나를다시살려주셨군요.”\n",
      "“나와결혼해주시겠어요?”\n",
      "“네, 좋아요!”\n",
      "두사람은일곱난쟁이와함께오래오래행복하게살\n",
      "았답니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 0, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, 'page_content': '백설공주\\n옛날어느왕국에공주님이태어났어요.\\n“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\\n설공주라고불러야겠다.”\\n왕과왕비는갓태어난딸을보며기뻐했어요.\\n하지만기쁨도잠시, 왕비는곧세상을떠나고말았어\\n요.\\n', 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 문서 분할(Split Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수 : 21\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 100, chunk_overlap = 10)\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의 수 : {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 임베딩(Embedding 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. DB 생성(백스토어 생성) 및 저장\n",
    "- FAISS(Facebook AI Similarity Search)\n",
    "    - 페이스북에서 개발한 유사도 검색 및 클러스터링 라이브러리\n",
    "    - 백터 데이터셋에서 빠른 유사도 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\20114\\miniforge3\\envs\\langchain_env\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\20114\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\20114\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from faiss-cpu) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“우아, 공주님이살아났어!”\n",
      "어어? 이상하다! 모든게일곱. 의자도일곱, 접시도일곱. 어머, \n",
      "침대도일곱개네.”\n",
      "도망치느라치진백설공주는식탁위에있던빵을먹고나서\n",
      "일곱번째침대에쓰러져잠들었어요.\n",
      "백설공주\n",
      "옛날어느왕국에공주님이태어났어요.\n",
      "“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\n",
      "설공주라고불러야겠다.”\n",
      "왕과왕비는갓태어난딸을보며기뻐했어요.\n",
      "“네, 좋아요!”\n",
      "두사람은일곱난쟁이와함께오래오래행복하게살\n",
      "았답니다.\n"
     ]
    }
   ],
   "source": [
    "for doc in vectorstore.similarity_search(\"엄마\"):\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 검색기(Retriever) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 0, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='백설공주\\n옛날어느왕국에공주님이태어났어요.\\n“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\\n설공주라고불러야겠다.”\\n왕과왕비는갓태어난딸을보며기뻐했어요.'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 4, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='저녁이되자, 일곱난쟁이가돌아왔어요.\\n난쟁이들은쓰러진백설공주를보고엉엉울었어요.\\n백설공주는깊은잠에빠진것처럼보였지요.\\n“백설공주님, 못된왕비의꾐에넘어갔군요.”'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 4, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='왕자는백설공주에게반해유리관을달라고부탁했어요.\\n일곱난쟁이는백설공주를잘지킨다는약속을받고유리관을\\n내주었지요.\\n그런데신하들이유리관을옮기다돌부리에툭! 백설공주목\\n에서사과조각이툭!'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 3, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='간사과랍니다. 잠깐문을열어보세요.”\\n백설공주는고개를저었어요.\\n“난쟁이들이문을열어주지말라고했어요.”\\n백설공주가거절하자, 왕비는창문틈새로사과를쑥내밀었어\\n요.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 백터스토어에 있는 정보를 검색하고 생성\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "retriver.invoke(\"백설공주와 일곱난쟁이는 어디서 만났어?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 프롬프트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 당신은 질문-답변 작업을 위한 어시스턴트입니다.\n",
    "- 주어진 문맥을 사용하여 질문에 대답하세요\n",
    "- 유치원 선생님이 아이에게 말하는 것처럼 매우 친절하고 부드러운 어조를 사용하세요\n",
    "- 따뜻하고 친절한 방식으로 말하세요\n",
    "- 답을 모르는 경우에는 모른다고 말하세요\n",
    "- 한국어로 대답하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "Use a very kind and gentle tone like a kindergarten teacher talking to a child.\n",
    "Speak in a warm and friendly way.\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. LLM 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# RunnablePassthrough -> 그대로 전달해주는 것\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriver, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미안하지만, 백설공주가 먹은 사과에 어떤 독이 있었는지는 알 수 없어요. 하지만 사과를 먹고 백설공주가 정신을 잃고 쓰러졌다는 이야기가 있네요.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행\n",
    "question = \"백설공주가 먹은 사과에는 어떤 독이 있었어?\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지 수 : 25\n",
      "분할된 청크의 수 : 86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/SPRi-AI-Brief.pdf', 'file_path': 'data/SPRi-AI-Brief.pdf', 'page': 20, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='근로자의 41%는 일자리 시장이 나쁘다고 인식\\n∙일자리 시장이 나쁘다고 인식하는 미국 근로자의 58%는 AI 발전으로 일자리가 줄어들 것으로 \\n예상했으며, 일자리 시장이 좋다고 답변한 근로자 중에서는 일자리가 줄어들 것이라는 응답이 32%를 기록\\n∙전체 근로자 중에서는 48%가 AI 발전으로 일자리가 줄어들 것이라고 답했으며, AI 발전으로 \\n일자리가 늘어날 것이라는 응답은 11%, 영향이 없을 것이라는 응답은 28%를 기록\\nn 미국 근로자의 27%는 직장에서 AI 도구를 주 1회 이상 사용하며, 전혀 사용하지 않는 비율은 49%를 기록\\n∙2023년 7월에는 직장에서 AI 도구를 주 1회 이상 사용한다는 응답 비율이 20%였으며, 2024년 3월, \\n8월에는 해당 응답이 각각 25%, 27%로 증가\\nn 미국 근로자의 34%는 AI로 인한 실직이나 근무 시간 또는 급여가 줄어들 가능성을 우려하고 있으며, 이 \\n수치는 2023년 7월 이래 비슷한 수준을 유지'),\n",
       " Document(metadata={'source': 'data/SPRi-AI-Brief.pdf', 'file_path': 'data/SPRi-AI-Brief.pdf', 'page': 22, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='∙반면, 유통 분야는 2028년까지 24만 개의 일자리가 줄어들 수 있으며, 제조업과 금융 서비스 분야도 \\n각각 9만 개와 5만 개의 일자리가 감소 예상\\n∙AI와 같은 복잡한 기술의 구현과 유지 관리를 위해 40만 개의 기술 일자리가 생겨날 전망으로, \\n컴퓨터와 정보시스템 관리, 개발 및 데이터 엔지니어링 분야가 특히 유망\\nn AI는 새로운 일자리를 창출하는 동시에 일상 업무의 자동화를 통해 기존 근로자의 생산성을 개선할 \\n전망으로, AI는 영국 내 정규직 288만 명에 상당하는 작업을 수행 가능\\n∙시스템 관리자와 같은 기술 분야의 직원은 AI 활용으로 주당 최대 12.6시간을 절약하여 남는 시간을 \\n더욱 복잡한 작업에 투입 가능\\n£ 글로벌 인재 수요, 2028년까지 기술직을 중심으로 증가 전망\\nn 서비스나우는 영국 외 독일, 미국, 싱가포르, 인도, 일본, 캐나다, 호주의 인력 추이를 조사한 결과\\n를 바탕으로 2028년까지 글로벌 인재 수요가 공급을 계속해서 앞지를 것으로 예상'),\n",
       " Document(metadata={'source': 'data/SPRi-AI-Brief.pdf', 'file_path': 'data/SPRi-AI-Brief.pdf', 'page': 6, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='정책 입안자와 대중에게 신뢰할 수 있는 정보를 제공\\n∙(AI 정책 대화) 포괄적이고 다중 이해관계자를 포함하는 AI 거버넌스 정책 대화를 시작하여 모범 \\n사례를 공유하고 국가 및 지역적 접근방식 간의 조정 및 상호운용성을 개선\\n∙(AI 표준 교류 체계 마련) 다양한 표준 개발 기구, 기술 기업, 시민사회 대표들 간 AI 표준 교류를 위한 \\n포괄적인 체계를 마련해 개방적이고 상호 운용이 가능하며 신뢰할 수 있는 AI 생태계 구축\\n∙(AI 역량 개발 네트워크 구축) 공공 및 민간 부문의 모든 사람이 AI를 책임 있고 윤리적으로 사용할 수 \\n있도록 포괄적이고 공평한 AI 역량 개발 네트워크를 구축\\n∙(AI 글로벌 기금 조성) AI 혁신과 역량 구축을 위한 글로벌 기금을 조성해 AI 및 지속가능발전목표(SDG)* \\n관련 프로젝트에 자금을 지원하고, 특히 저소득 및 중간 소득 국가의 요구 사항을 우선 추진'),\n",
       " Document(metadata={'source': 'data/SPRi-AI-Brief.pdf', 'file_path': 'data/SPRi-AI-Brief.pdf', 'page': 21, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='1. 정책/법제  \\n2. 기업/산업 \\n3. 기술/연구 \\n 4. 인력/교육\\n19\\nIBM 기업가치연구소, ‘생성 AI 시대 인적 잠재력 재해석’ 보고서 발간\\nn IBM 기업가치연구소에 따르면 생성 AI는 직원의 잠재력 발견과 업무 흐름을 혁신해 기업의 \\n새로운 미래를 개척할 수 있으며, 이를 위해 미래 업무에 대한 비전 수립이 필요\\nn 인사관리 부문은 AI 도구를 통해 직원의 성과 향상과 잠재력 발휘를 지원할 수 있으며, 생성 \\nAI를 활용한 혁신을 위해서는 위험을 감수하는 기업 문화의 조성 필요\\nKEY Contents\\n£ 생성 AI 기반의 인적 잠재력을 위해 미래 업무에 대한 비전 수립 필요\\nn IBM 기업가치연구소가 20개국 20개 산업 1,000명의 임원진 대상 설문조사를 바탕으로 2024년 9월 \\n3일 ‘생성 AI 시대의 인적 잠재력 재해석’에 관한 보고서를 발간\\n∙기업이 생성 AI를 통한 프로세스 간소화와 자동화에만 집중하나, 생성 AI는 직원의 잠재력 발견과')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다시 해보기\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "#PYMUPDFLoader 객체 정의\n",
    "loader = PyMuPDFLoader(\"data/SPRi-AI-Brief.pdf\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 페이지 수 : {len(docs)}\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 30)\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의 수 : {len(split_documents)}\")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "retriver.invoke(\"AI 시장에 대한 긍정적인 측면\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친구야, AI 시장이 커지면 문제점이 뭐냐고? 음, 이건 마치 내가 다이어트한다고 하면서 매일 밤 치킨을 먹는 것과 비슷한 문제야. 겉으로는 좋아 보이지만, 속으로는 문제가 생길 수 있지! 😂\n",
      "\n",
      "일단, AI가 발전하면서 일자리가 줄어들 거라는 걱정이 많아. 미국 근로자의 48%가 AI 때문에 일자리가 줄어들 거라고 생각한대. 이건 마치 내가 다이어트한다고 하면서도 치킨을 포기 못하는 것처럼, AI가 발전해도 일자리가 줄어드는 건 피할 수 없는 현실인 것 같아. (참고한 페이지: 20페이지)\n",
      "\n",
      "그리고 유통, 제조업, 금융 서비스 분야에서도 일자리가 줄어들 거라고 하더라고. 하지만 반대로 AI 기술을 다루는 새로운 일자리가 생길 거라니, 이건 마치 치킨을 먹으면서도 운동을 열심히 해서 살을 빼는 것 같은 느낌이야! (참고한 페이지: 22페이지)\n",
      "\n",
      "또한, AI가 발전하면서 실직이나 근무 시간, 급여가 줄어들 가능성에 대해 걱정하는 사람들도 많아. 하지만 63%는 낙관적이라니, 이건 마치 내가 치킨을 먹으면서도 내일은 꼭 운동할 거라고 다짐하는 것과 비슷한 것 같아. (참고한 페이지: 20페이지)\n",
      "\n",
      "결론적으로, AI 시장이 커지면서 일자리 문제와 같은 걱정이 있지만, 새로운 기회도 생길 수 있다는 거지. 그러니 우리도 AI와 함께 잘 적응해보자고! 😄\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Say it like you're talking to a friend and throw in a bunch of jokes!\n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    "\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# RunnablePassthrough -> 그대로 전달해주는 것\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriver, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "question = \"AI시장이 커질수록 문제점은 뭐야? 어떤 페이지를 기반으로 답변하는건지 참고한 페이지도 함께 알려줘\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement SoupStrainerw (from versions: none)\n",
      "ERROR: No matching distribution found for SoupStrainerw\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 문맥에서는 \"아파트\"가 로제와 브루노 마스가 함께 부른 노래 제목으로 언급되고 있습니다. 따라서 아파트의 층수에 대한 정보는 제공되지 않았습니다. 죄송하지만, 이 문맥에서는 아파트의 층수를 알 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 환경변수 가져오기\n",
    "load_dotenv()\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=(\"https://n.news.naver.com/article/437/0000416134\"),\n",
    "    bs_kwargs=dict(\n",
    "        # 특정 요소에서만 파싱하도록 제한하는 필터 적용\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\":[\"newsct_article _article_body\", \"media_and_head go_trans\"]}\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# print(docs)\n",
    "\n",
    "# 문서분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 임베딩 생성\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 백터 스토어 생성\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
    "\n",
    "# 검색기 (retriver) 생성\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "# runtime\n",
    "\n",
    "# 프롬프트\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 질문-답변을 수행하는 AI 어시스턴트이다.\n",
    "    주어진 문맥에 검색된 다음문맥(context)를 사용해 질문에 답해야 한다.\n",
    "    \n",
    "    만약 주어진 문맥에서 답을 찾을 수 없는 경우, 모른다고 답해야 한다.\n",
    "    주어진 질문에 대해서는 한글로 답변해야 한다.\n",
    "    \n",
    "    #Question\n",
    "    {question}\n",
    "    \n",
    "    #Context\n",
    "    {context}\n",
    "    \n",
    "    #Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# LLM 모델\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# chain 구성\n",
    "news_chain = (\n",
    "    {\"context\":retriver, \"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 질문\n",
    "answer = news_chain.invoke(\"아파트는 몇 층이야?\")\n",
    "print(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
